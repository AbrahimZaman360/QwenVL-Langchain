# QwenVL - Vision Language Models (multi-models) Support for Langchain:
Use the following wrapper for QwenVL and based on this you can create wrappers for other VL Models easily (:

- Input Supported Modes:
1. Text2Text Generation
2. Imag2Text Generation
3. Audio2Text Generation (coming soon)
4. Video2Text Generation (coming soon)


- Use llm.destruct_model_Inferencing()
function to Unload the Model from GPU Memory
